---
title: "Forecasting: principles and practice"
author: "Rob J Hyndman"
date: "2.5&nbsp; Seasonal ARIMA models"
fontsize: 14pt
output:
  beamer_presentation:
    fig_width: 7
    fig_height: 4.3
    highlight: tango
    theme: metropolis
    includes:
      in_header: header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  cache=TRUE,
  warning=FALSE,
  message=FALSE)
library(fpp2)
options(digits=4, width=55)
```

# Seasonal ARIMA models

## Seasonal ARIMA models

| ARIMA | $~\underbrace{(p, d, q)}$ | $\underbrace{(P, D, Q)_{m}}$ |
| ----: | :-----------------------: | :--------------------------: |
|       | ${\uparrow}$              | ${\uparrow}$                 |
|       | Non-seasonal part         | Seasonal part of             |
|       | of the model              | of the model                 |

where $m =$ number of observations per year.

## Seasonal ARIMA models

E.g., ARIMA$(1, 1, 1)(1, 1, 1)_{4}$  model (without constant)\pause
$$(1 - \phi_{1}B)(1 - \Phi_{1}B^{4}) (1 - B) (1 - B^{4})y_{t} ~= ~
(1 + \theta_{1}B) (1 + \Theta_{1}B^{4})\varepsilon_{t}.
$$\pause

\setlength{\unitlength}{1mm}
\begin{footnotesize}
\begin{picture}(100,25)(-5,0)
\thinlines
{\put(5,22){\vector(0,1){6}}}
{\put(22,10){\vector(0,1){18}}}
{\put(38,22){\vector(0,1){6}}}
{\put(52,10){\vector(0,1){18}}}
{\put(77,22){\vector(0,1){6}}}
{\put(95,10){\vector(0,1){18}}}
{\put(-10,17){$\left(\begin{array}{@{}c@{}} \text{Non-seasonal} \\ \text{AR(1)}
                    \end{array}\right)$}}
{\put(12,5){$\left(\begin{array}{@{}c@{}} \text{Seasonal} \\ \text{AR(1)}
                    \end{array}\right)$}}
{\put(25,17){$\left(\begin{array}{@{}c@{}} \text{Non-seasonal} \\ \text{difference}
                    \end{array}\right)$}}
{\put(40,5){$\left(\begin{array}{@{}c@{}} \text{Seasonal} \\ \text{difference}
                    \end{array}\right)$}}
{\put(65,17){$\left(\begin{array}{@{}c@{}} \text{Non-seasonal} \\ \text{MA(1)}
                    \end{array}\right)$}}
{\put(85,5){$\left(\begin{array}{@{}c@{}} \text{Seasonal} \\ \text{MA(1)}
                    \end{array}\right)$}}
\end{picture}
\end{footnotesize}

\vspace*{10cm}

## Seasonal ARIMA models

E.g., ARIMA$(1, 1, 1)(1, 1, 1)_{4}$  model (without constant)
$$(1 - \phi_{1}B)(1 - \Phi_{1}B^{4}) (1 - B) (1 - B^{4})y_{t} ~= ~
(1 + \theta_{1}B) (1 + \Theta_{1}B^{4})\varepsilon_{t}.
$$

All the factors can be multiplied out and the general model
written as follows:
\begin{align*}
y_{t}  &= (1 + \phi_{1})y_{t - 1} - \phi_1y_{t-2} + (1 + \Phi_{1})y_{t - 4}\\
&\text{}
 -  (1  + \phi_{1}  +  \Phi_{1} + \phi_{1}\Phi_{1})y_{t - 5}
 +  (\phi_{1}  +  \phi_{1} \Phi_{1}) y_{t - 6} \\
& \text{}  - \Phi_{1} y_{t - 8} +  (\Phi_{1}  +  \phi_{1} \Phi_{1}) y_{t - 9}
  - \phi_{1} \Phi_{1} y_{t  -  10}\\
  &\text{}
+    \varepsilon_{t} + \theta_{1}\varepsilon_{t - 1} + \Theta_{1}\varepsilon_{t - 4}  + \theta_{1}\Theta_{1}\varepsilon_{t - 5}.
\end{align*}
\vspace*{10cm}

## Common ARIMA models

The US Census Bureau uses the following models most often:\vspace*{0.5cm}

\begin{tabular}{|ll|}
\hline
ARIMA(0,1,1)(0,1,1)$_m$& with log transformation\\
ARIMA(0,1,2)(0,1,1)$_m$& with log transformation\\
ARIMA(2,1,0)(0,1,1)$_m$& with log transformation\\
ARIMA(0,2,2)(0,1,1)$_m$& with log transformation\\
ARIMA(2,1,2)(0,1,1)$_m$& with no transformation\\
\hline
\end{tabular}

## Understanding ARIMA models
\fontsize{14}{16}\sf

\begin{alertblock}{Long-term forecasts}
\centering\begin{tabular}{lll}
zero & $c=0,d+D=0$\\
non-zero constant & $c=0,d+D=1$ & $c\ne0,d+D=0$  \\
linear & $c=0,d+D=2$ & $c\ne0,d+D=1$ \\
quadratic & $c=0,d+D=3$ & $c\ne0,d+D=2$ \\
\end{tabular}
\end{alertblock}

### Forecast variance and $d+D$
  * The higher the value of $d+D$, the more rapidly the prediction intervals increase in size.
  * For $d+D=0$, the long-term forecast standard deviation will go to the standard deviation of the historical data.

## European quarterly retail trade

```{r, echo=TRUE, fig.height=3.6}
autoplot(euretail) +
  xlab("Year") + ylab("Retail index")
```

## European quarterly retail trade

```{r, echo=TRUE, fig.height=4}
euretail %>% diff(lag=4) %>% autoplot()
```

## European quarterly retail trade

```{r, echo=TRUE, fig.height=3.8}
euretail %>% diff(lag=4) %>% diff() %>%
  autoplot()
```

## European quarterly retail trade
\fontsize{11}{12}\sf

```{r euretail, echo=TRUE}
(fit <- auto.arima(euretail))
```
## European quarterly retail trade
\fontsize{11}{12}\sf

```{r euretail2, echo=TRUE}
(fit <- auto.arima(euretail, stepwise=TRUE,
  approximation=FALSE))
```

## European quarterly retail trade
\fontsize{13}{13}\sf

```{r, dependson='euretail2'}
checkresiduals(fit, test=FALSE)
```

## European quarterly retail trade
\fontsize{13}{13}\sf

```{r, dependson='euretail2'}
checkresiduals(fit, plot=FALSE)
```

## European quarterly retail trade
\fontsize{13}{13}\sf

```{r, dependson='euretail2'}
forecast(fit, h=36) %>% autoplot()
```

## Cortecosteroid drug sales

```{r h02, echo=FALSE}
lh02 <- log(h02)
tmp <- cbind("H02 sales (million scripts)" = h02,
             "Log H02 sales"=lh02)
autoplot(tmp, facets=TRUE) + xlab("Year") + ylab("")
```

## Cortecosteroid drug sales
\fontsize{13}{14}\sf

```{r h02b}
autoplot(diff(log(h02),12), xlab="Year",
  main="Seasonally differenced H02 scripts")
```

## Cortecosteroid drug sales
\fontsize{10}{14}\sf

```{r h02tryharder, echo=TRUE, fig.height=3.6}
(fit <- auto.arima(h02, lambda=0, max.order=9,
  stepwise=FALSE, approximation=FALSE))
```

## Cortecosteroid drug sales
\fontsize{13}{15}\sf

```{r, echo=TRUE, fig.height=4, dependson='h02tryharder'}
checkresiduals(fit)
```

## Cortecosteroid drug sales
\fontsize{13}{15}\sf

```{r, echo=FALSE, dependson='h02tryharder'}
checkresiduals(fit, plot=FALSE)
```

## Cortecosteroid drug sales
\fontsize{10}{12}\sf

Training data: July 1991 to June 2006

Test data: July 2006--June 2008

```r
getrmse <- function(x,h,...)
{
  train.end <- time(x)[length(x)-h]
  test.start <- time(x)[length(x)-h+1]
  train <- window(x,end=train.end)
  test <- window(x,start=test.start)
  fit <- Arima(train,...)
  fc <- forecast(fit,h=h)
  return(accuracy(fc,test)[2,"RMSE"])
}
getrmse(h02,h=24,order=c(3,0,0),seasonal=c(2,1,0),lambda=0)
getrmse(h02,h=24,order=c(3,0,1),seasonal=c(2,1,0),lambda=0)
getrmse(h02,h=24,order=c(3,0,2),seasonal=c(2,1,0),lambda=0)
getrmse(h02,h=24,order=c(3,0,1),seasonal=c(1,1,0),lambda=0)
getrmse(h02,h=24,order=c(3,0,1),seasonal=c(0,1,1),lambda=0)
getrmse(h02,h=24,order=c(3,0,1),seasonal=c(0,1,2),lambda=0)
getrmse(h02,h=24,order=c(3,0,1),seasonal=c(1,1,1),lambda=0)
getrmse(h02,h=24,order=c(3,0,3),seasonal=c(0,1,1),lambda=0)
getrmse(h02,h=24,order=c(3,0,2),seasonal=c(0,1,1),lambda=0)
getrmse(h02,h=24,order=c(2,1,3),seasonal=c(0,1,1),lambda=0)
getrmse(h02,h=24,order=c(2,1,4),seasonal=c(0,1,1),lambda=0)
getrmse(h02,h=24,order=c(2,1,5),seasonal=c(0,1,1),lambda=0)
getrmse(h02,h=24,order=c(4,1,1),seasonal=c(2,1,2),lambda=0)
```

## Cortecosteroid drug sales
\fontsize{12}{14}\sf

```{r, cache=TRUE, echo=FALSE}
models <- rbind(
  c(3,0,0,2,1,0),
  c(3,0,1,2,1,0),
  c(3,0,2,2,1,0),
  c(3,0,1,1,1,0),
  c(3,0,1,0,1,1),
  c(3,0,1,0,1,2),
  c(3,0,1,1,1,1),
  c(4,0,3,0,1,1),
  c(3,0,3,0,1,1),
  c(4,0,2,0,1,1),
  c(3,0,2,0,1,1),
  c(2,1,3,0,1,1),
  c(4,1,1,2,1,2),
  c(4,1,2,2,1,2),
  c(3,1,2,2,1,2),
  c(4,1,2,1,1,2),
  c(4,1,2,2,1,1),
  c(2,1,4,0,1,1),
  c(2,1,5,0,1,1))
h <- 24
train.end <- time(h02)[length(h02)-h]
test.start <- time(h02)[length(h02)-h+1]
train <- window(h02,end=train.end)
test <- window(h02,start=test.start)

rmse <- numeric(NROW(models))
modelname <- character(NROW(models))
for(i in seq(length(rmse)))
{
  fit <- Arima(train, order=models[i,1:3],
          seasonal=models[i,4:6], lambda=0)
  fc <- forecast(fit,h=h)
  rmse[i] <- accuracy(fc, test)[2,"RMSE"]
  modelname[i] <- as.character(fit)
}
k <- order(rmse)
knitr::kable(data.frame(Model=modelname[k],RMSE=rmse[k]),
             digits=4)
```

## Cortecosteroid drug sales

  * Models with lowest AICc values tend to give slightly better results than the other models.
  * AICc comparisons must have the same orders of differencing. But RMSE test set comparisons can involve any models.
  * Use the best model available, even if it does not pass all tests.

## Cortecosteroid drug sales
\fontsize{11}{12}\sf

```{r h02fa, echo=TRUE, fig.height=3.4}
fit <- Arima(h02, order=c(4,1,1), seasonal=c(2,1,2),
  lambda=0)
autoplot(forecast(fit)) + xlab("Year") +
  ylab("H02 sales (million scripts)") + ylim(0.3,1.8)
```

## Cortecosteroid drug sales
\fontsize{11}{12}\sf

```{r h02fb, echo=TRUE, fig.height=3.4}
fit <- Arima(h02, order=c(4,1,2), seasonal=c(2,1,2),
  lambda=0)
autoplot(forecast(fit)) + xlab("Year") +
  ylab("H02 sales (million scripts)") + ylim(0.3,1.8)
```

## Cortecosteroid drug sales
\fontsize{11}{12}\sf

```{r h02fc, echo=TRUE, fig.height=3.4}
fit <- Arima(h02, order=c(3,0,1), seasonal=c(0,1,2),
  lambda=0)
autoplot(forecast(fit)) + xlab("Year") +
  ylab("H02 sales (million scripts)") + ylim(0.3,1.8)
```

# Lab session 17
##
\fontsize{48}{60}\sf\centering
**Lab Session 17**

# ARIMA vs ETS

## ARIMA vs ETS

  * Myth that ARIMA models are more general than exponential smoothing.
  * Linear exponential smoothing models all special cases of ARIMA models.
  * Non-linear exponential smoothing models have no equivalent ARIMA counterparts.
  * Many ARIMA models have no exponential smoothing counterparts.
  * ETS models all non-stationary. Models with seasonality or non-damped trend (or both) have two unit roots; all other models have one unit root.

## Equivalences
\fontsize{12}{14}\sf

|**ETS model**  | **ARIMA model**             | **Parameters**                       |
| :------------ | :-------------------------- | :----------------------------------- |
| ETS(A,N,N)    | ARIMA(0,1,1)                | $\theta_1 = \alpha-1$                |
| ETS(A,A,N)    | ARIMA(0,2,2)                | $\theta_1 = \alpha+\beta-2$          |
|               |                             | $\theta_2 = 1-\alpha$                |
| ETS(A,Ad,N)    | ARIMA(1,1,2)                | $\phi_1=\phi$                        |
|               |                             | $\theta_1 = \alpha+\phi\beta-1-\phi$ |
|               |                             | $\theta_2 = (1-\alpha)\phi$          |
| ETS(A,N,A)    | ARIMA(0,0,$m$)(0,1,0)$_m$   |                                      |
| ETS(A,A,A)    | ARIMA(0,1,$m+1$)(0,1,0)$_m$ |                                      |
| ETS(A,Ad,A)    | ARIMA(1,0,$m+1$)(0,1,0)$_m$ |                                      |

# Lab session 18
##
\fontsize{48}{60}\sf\centering
**Lab Session 18**
